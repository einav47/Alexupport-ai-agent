"""
This module defines the IsRelevantAgent microagent,
which is responsible for determining the relevance of the generated response
to the user's question.
"""

from typing import List

from agent.llm_client import LLMClient
from utils.utils import clean_string

class IsRelevantAgent:
    """Microagent for determining the relevance of the generated response"""

    def __init__(self, llm_client: LLMClient):
        self.llm_client = llm_client
        self.system_prompt = """
        You are a quality assurance specialist for Amazon product support.
        Given a question, and an answer your task is to verify if a generated answer is relevant, accurate, and helpful.

        Evaluate the answer based on:
        1. Does it directly address the user's question?
        2. Is it based on the provided information?
        3. Is it helpful and informative?
        4. Does it avoid speculation or generic responses?
        5. Is it written in a clear, professional tone?

        Respond with only "YES" if the answer is good, or "NO" if it needs improvement.
        """

    def assess_relevance(self, user_question: str, generated_response: str, context: List[List[str]]) -> (bool, str):
        """
        Assesses the relevance of the generated response to the user question.

        Parameters:
        - user_question: str; The question posed by the user.
        - generated_response: str; The response generated by the model.
        - context: List[str]; The context information retrieved for the product.

        Returns:
        - tuple: (bool, str); True if the generated response is relevant, False otherwise, along with a reason.
        """

        complete_human_input = clean_string(f"""
        Based on the following information, determine if the generated answer is relevant and helpful.

        Original question: {user_question}

        Context: {context}

        Generated answer: {generated_response}

        Provide a simple "YES" or "NO" response based on the answer's relevance and helpfulness.
        Do not provide any additional explanations or details other than your "YES" or "NO" answer.
        """)

        messages = [
            {"role": "system", "content": self.system_prompt},
            {"role": "human", "content": complete_human_input}
        ]

        try:
            response = self.llm_client.generate_response(messages=messages).strip().upper()
            if response.startswith("YES"):
                return True, "The generated response is relevant and helpful."
            elif response.startswith("NO"):
                return False, "I couldn't find a relevant answer to your question."
            else:
                return False, f"Unexpected response from LLM: {response}"
        except Exception as e:
            return False, f"Error during relevance assessment: {e}"
