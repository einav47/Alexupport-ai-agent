# ü§ñ Alexupport - Amazon Product Support Assistant

An autonomous AI agent built with LangChain that provides customer support for Amazon products using real customer Q&A data and verified information.

## üèóÔ∏è Agent structure & workflow

The Alexupport agent is comprised of several microagents in the `agents` directory:

* **Input Refiner microagent**: Implemented in the `input_refiner.py` file, this microagent refines the user input by fixing typos/grammatical errors, expanding abbreviations and clarifying ambiguous terms.
* **Information Retriever microagent**: Implemented in the `information_retrever.py` file, this microagent retrieves the relevant data from the Qdrant vectorstore by comparing it to the (refined) user input.
* **Is-Answerable microagent**: Implemented in the `is_answerable_agent.py` file, this microagent determines if the (refined) input question can be answered using the retrieved data.
* **Answer Generator microagent**: Implemented in the `answer_generator.py` file, this microagent generates an answer to the user's question based on the retrieved information and the chat history (if available).
* **Follow-up Generator microagent**: Implemented in the `followup-generator.py` file, this microagent generates follow-up questions based on the retrieved information and the chat history (if available).
* **Is-Relevant microagent**: Implemented in the `is_relevant_agent.py` file, this microagent determines if the generated answer from the Answer Generator microagent answers the user's query.

The above components create the complete Alexupport workflow - given a user question, the Alexupport agent:

1. Refines the user query by fixing typos and grammar, and expanding abbreviations.
2. Retrieves relevant data from the Qdrant collction using similary search (using the cosine similarity metric).
3. Determines if the retrieved data can be used to answer the user's query:
    * If the agent determines that the retrieved data is sufficient for answering the suer's query, we proceed to step 4.
    * Otherwise, responds with "I can't answer that question".
4. Iterates up to 5 times:
    1. Generates an answer based on the retrieved data.
    2. Determines if the generated answer is relevant to the user's query:
        * If it is, generates follow-up questions and returns them to the user, along with the generated answer.
        * Otherwise, moves to the next iteration.
5. If all 5 iterations are done, the agent generates follow-up questions and responds with the last generated answer.

The complete Alexupport agent is built under the `alexupport_agent.py` file, which integrates the mentioned microagents into a complete pipeline, as described above.

## üìö Data

Alexupport uses [the AmazonQA dataset](https://github.com/amazonqa/amazonqa) - a large review-based Question Answering dataset. We use Qdrant as out vector database to store the data, along with its embedding vectors, to later query it, based on the user's query. As a proof of concept of the Alexupport agent, we use only the validation part of the dataset (`val-qar.jsonl`).

Before loading the data to the Qdrant collection, we perform the following pre-processing steps:
* Filtering the data to keep only the records that satisfy:
    * `is_answerable = 1`: A boolean value that indicates that the question is answerable using the review snippets. We keep only the records which are labeled as answerable to make sure the data contains only valuable information.
    * `questionText` length `>= 5`: Keeping only the records with questions of 5+ words. This allows us to filter out garbage values.
    * `answers` length `>= 3`: Keeping only the records with questions that have at least 3 answers. This ensures that we have enough context to answer a given question.
    * `helpful[0]` indicators `> 0`: Keeping only the records where at least one answer has `helpful[0] > 0`. This ensures that the answers we keep were maked as helpful by users, indicating that they contain valuable information.
* Completing the missing `productTitle` key: the original AmazonQA dataset contains each product's `asin` (Unique product ID generated by Amazon), and does not contain the title of each product. We complete this value by scraping it directly from Amazon.com and adding it to the dataset.
* Finally, we discard the records without `productTitle`.

These steps reduce the number of unqiue items to 163 and the number of records to 1246, maintaing only the clean and filtered information we require for the agent.

## ‚öíÔ∏è Setup

1. **Create a Python 3.11 virtual environment and activate it**
    ```bash
    python3.11 -m venv .venv
    source .venv/bin/activate
    ```

2. **Install dependencies**
    ```bash
    pip install -r requirements.txt
    ```

3. **Set the AzureOpenAI `AZURE_OPENAI_API_KEY` environment variable in the `.env` file**
    ``` bash
    echo AZURE_OPENAI_API_KEY="<your-api-key>" > .env
    ```

4. **Run the agent (using the Streamlit UI)**
    ```bash
    python main.py
    ```
